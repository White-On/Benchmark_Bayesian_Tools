[InferenceRandomBN]
nb_runs = 1
keyword = bif,Bayesian network
arguments = BN_12_1.5_3.bif,BN_16_1.5_3.bif,BN_15_1.5_3.bif,BN_10_1.5_3.bif,BN_11_1.5_2.bif,BN_12_1.5_3.bif,BN_13_1.5_2.bif,BN_11_1.5_2.bif,BN_11_1.5_3.bif,BN_17_1.5_3.bif
before_task = python before_task.py
timeout = 60
description = Inference is the process of using a Bayesian Network to compute the probability of an event given some evidence or observations. Bayesian Networks are graphical models that represent the relationships between random variables using directed acyclic graphs. Each node in the graph represents a random variable, and the edges represent the conditional dependencies between them. Inference can be used to answer questions like "What is the probability of a certain event occurring, given that some other event has already occurred?" or "What is the most likely value of a certain variable, given some observed data?" Inference can also be used to propagate uncertainty through the network, allowing us to reason about the probabilities of complex events that depend on multiple variables. The Inference task in a benchmark of Bayesian Network libraries would typically involve measuring the speed and accuracy of various methods for performing inference on a given Bayesian Network. This could include methods like exact inference, approximate inference using Monte Carlo methods, or message-passing algorithms like belief propagation. To perform the Inference task, a benchmarking tool would typically provide a set of test cases, each consisting of a Bayesian Network and some evidence or observations. The tool would then run each of the inference methods being tested on each test case, measuring the time required to perform the inference and the accuracy of the results obtained. The results of the benchmark could then be used to compare the performance and accuracy of different Bayesian Network libraries for the task of inference.
arguments_description = Bayesian network
display_scale = linear