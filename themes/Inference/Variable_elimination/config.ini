[Variable_elimination]
; nb_runs = 30
arguments = cancer.bif,earthquake.bif,asia.bif,child.bif,insurance.bif,water.bif,mildew.bif,alarm.bif,barley.bif,hailfinder.bif,hepar2.bif,andes.bif,diabetes.bif,pigs.bif,link.bif,munin.bif
keyword = bif,Bayesian network, Learning structure, Learning parameters

timeout = 180
arguments_description = Files Infered On

description = Variable Elimination is a technique used in probabilistic graphical models, such as Bayesian Networks, to perform probabilistic inference efficiently. It's used to compute the probability distribution of one or more variables given evidence about other variables.
    In a Bayesian Network, variables are represented as nodes, and the connections between nodes indicate probabilistic dependencies. Variable Elimination exploits the structure of the network to simplify complex computations. Here's a simplified explanation of the process:
    1. **Initialization**: Start with the full joint distribution of all variables in the network.
    2. **Message Passing**: Traverse the network in a way that respects the network's structure, usually starting from the observed evidence variables. Messages are passed between nodes, representing how the information flows through the network.
    3. **Elimination**: When encountering a node with multiple parents, "eliminate" it by summing out the variable it represents. This is done using the passed messages to compute the marginal probabilities efficiently.
    4. **Propagation**: Continue passing messages and eliminating nodes until you've reached the query variable(s) you're interested in. The final result is the marginal probability distribution of the query variable(s) given the evidence.
    Variable Elimination reduces the computational complexity of probabilistic inference by exploiting the conditional independence properties encoded in the Bayesian Network. It eliminates the need to explicitly compute the entire joint distribution, which can be prohibitively expensive for larger networks.
    This technique is crucial for efficiently answering probabilistic queries in Bayesian Networks and other probabilistic graphical models.

extra_description = In a Bayesian Network, variables are represented as nodes, and the connections between nodes indicate probabilistic dependencies. Variable Elimination exploits the structure of the network to simplify complex computations. Here's a simplified explanation of the process:
    1. **Initialization**: Start with the full joint distribution of all variables in the network.
    2. **Message Passing**: Traverse the network in a way that respects the network's structure, usually starting from the observed evidence variables. Messages are passed between nodes, representing how the information flows through the network.
    3. **Elimination**: When encountering a node with multiple parents, "eliminate" it by summing out the variable it represents. This is done using the passed messages to compute the marginal probabilities efficiently.
    4. **Propagation**: Continue passing messages and eliminating nodes until you've reached the query variable(s) you're interested in. The final result is the marginal probability distribution of the query variable(s) given the evidence.
    Variable Elimination reduces the computational complexity of probabilistic inference by exploiting the conditional independence properties encoded in the Bayesian Network. It eliminates the need to explicitly compute the entire joint distribution, which can be prohibitively expensive for larger networks.
    This technique is crucial for efficiently answering probabilistic queries in Bayesian Networks and other probabilistic graphical models.


task_scale = auto
post_task_scale = auto

task_xlabel = Files Infered On
task_ylabel = Time (s)
task_title = Inference time by Variable Elimination
task_display = groupedBar

active = True